{
 "cells": [
  {
   "cell_type": "code",
   "source": "# Set conda environment for proper GPU support\nimport os\nos.environ['CONDA_DEFAULT_ENV'] = 'trading-env'\n\n# Configure GPU\nimport tensorflow as tf\n\ndef configure_gpu():\n    \"\"\"Configure TensorFlow for optimal GPU usage.\"\"\"\n    print(\"üîß Configuring GPU settings...\")\n    \n    gpus = tf.config.list_physical_devices('GPU')\n    \n    if gpus:\n        try:\n            print(f\"üéÆ Found {len(gpus)} GPU(s):\")\n            for i, gpu in enumerate(gpus):\n                print(f\"  GPU {i}: {gpu}\")\n            \n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n                print(f\"  ‚úÖ Memory growth enabled for {gpu}\")\n            \n            policy = tf.keras.mixed_precision.Policy('mixed_float16')\n            tf.keras.mixed_precision.set_global_policy(policy)\n            print(\"  ‚úÖ Mixed precision enabled (float16)\")\n            \n            print(f\"  ‚úÖ GPU acceleration: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n            print(f\"  ‚úÖ GPU device name: {tf.config.list_physical_devices('GPU')[0].name if tf.config.list_physical_devices('GPU') else 'No GPU'}\")\n            \n            return True\n            \n        except RuntimeError as e:\n            print(f\"  ‚ùå GPU setup failed: {e}\")\n            return False\n    else:\n        print(\"  ‚ö†Ô∏è No GPUs found, using CPU\")\n        return False\n\ndef verify_gpu_usage():\n    \"\"\"Verify that TensorFlow is actually using GPU.\"\"\"\n    print(\"\\nüîç GPU Usage Verification:\")\n    \n    with tf.device('/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'):\n        a = tf.random.normal([1000, 1000])\n        b = tf.random.normal([1000, 1000])\n        c = tf.matmul(a, b)\n        \n        print(f\"  Test computation device: {c.device}\")\n        print(f\"  GPU available: {tf.config.list_physical_devices('GPU')}\")\n        \n    if tf.config.list_physical_devices('GPU'):\n        gpu_details = tf.config.experimental.get_device_details(tf.config.list_physical_devices('GPU')[0])\n        print(f\"  GPU details: {gpu_details}\")\n\ngpu_available = configure_gpu()\nverify_gpu_usage()\n\nif gpu_available:\n    print(\"\\n‚ö° GPU Optimization Settings Applied:\")\n    print(\"  - Memory growth enabled\")\n    print(\"  - Mixed precision training (float16)\")\n    print(\"  - GPU device verification completed\")\n    \n    tf.config.optimizer.set_jit(True)\n    print(\"  - XLA compilation enabled\")\nelse:\n    print(\"\\nüñ•Ô∏è CPU Optimization Settings:\")\n    tf.config.threading.set_intra_op_parallelism_threads(0)\n    tf.config.threading.set_inter_op_parallelism_threads(0)\n    print(\"  - Multi-threading enabled for CPU\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìà Clean CNN-LSTM Forex Trading Strategy (FIXED)\n",
    "\n",
    "This notebook implements a **robust, production-ready** CNN+LSTM hybrid model for forex price direction prediction with comprehensive error handling and data validation.\n",
    "\n",
    "## Overview\n",
    "- **Architecture**: CNN layers for feature extraction + LSTM for temporal patterns\n",
    "- **Features**: Technical indicators (RSI, MACD, ATR, etc.) + Relative Currency Strength\n",
    "- **Target**: Binary classification (price direction prediction)\n",
    "- **Data Source**: MetaTrader 5 or Yahoo Finance with fallbacks\n",
    "- **Export**: Trained models in H5 and ONNX formats\n",
    "- **Robustness**: Comprehensive error handling and data validation\n",
    "\n",
    "## Fixed Issues\n",
    "- ‚úÖ Import dependency error handling\n",
    "- ‚úÖ Data loading robustness with fallbacks\n",
    "- ‚úÖ Column name standardization\n",
    "- ‚úÖ Data validation and quality checks\n",
    "- ‚úÖ Memory management\n",
    "- ‚úÖ Index alignment safety\n",
    "- ‚úÖ Function signature corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "SYMBOLS = ['EURUSD', 'GBPUSD']  # Main trading pairs to predict\n",
    "ALL_SYMBOLS = [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"AUDUSD\", \"USDCAD\", \"EURJPY\", \"GBPJPY\"]  # For RCS calculation\n",
    "LOOKBACK_WINDOW = 20  # Number of time steps for sequence input\n",
    "TEST_SIZE = 0.2  # Proportion of data for testing\n",
    "VALIDATION_SIZE = 0.15  # Proportion of training data for validation\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "EARLY_STOPPING_PATIENCE = 10\n",
    "DROPOUT_RATE = 0.3\n",
    "\n",
    "# Data source configuration\n",
    "PROVIDER = \"yahoo\"  # Start with yahoo as more reliable fallback\n",
    "BROKER = \"amp_global\"\n",
    "INTERVAL = \"H1\"\n",
    "\n",
    "# Data quality thresholds\n",
    "MIN_DATA_POINTS = 500  # Minimum data points required\n",
    "MIN_TRAINING_SAMPLES = 100  # Minimum samples for training\n",
    "MAX_NAN_RATIO = 0.1  # Maximum proportion of NaN values allowed\n",
    "\n",
    "print(\"‚úÖ Configuration set\")\n",
    "print(f\"Target symbols: {SYMBOLS}\")\n",
    "print(f\"Lookback window: {LOOKBACK_WINDOW} periods\")\n",
    "print(f\"Data provider: {PROVIDER}\")\n",
    "print(f\"Minimum data points required: {MIN_DATA_POINTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import logging\n",
    "import gc\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Deep learning libraries\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential, Model\n",
    "    from tensorflow.keras.layers import (\n",
    "        Input, Conv1D, LSTM, Dense, Dropout, \n",
    "        BatchNormalization, concatenate\n",
    "    )\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from tensorflow.keras.regularizers import l1_l2\n",
    "    \n",
    "    # Configure TensorFlow memory growth\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"üéÆ GPU memory growth enabled!\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"‚ö†Ô∏è GPU setup warning: {e}\")\n",
    "    else:\n",
    "        print(\"üñ•Ô∏è No GPUs found, using CPU\")\n",
    "        \n",
    "    TF_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå TensorFlow import failed: {e}\")\n",
    "    TF_AVAILABLE = False\n",
    "\n",
    "# Technical analysis\n",
    "try:\n",
    "    import ta\n",
    "    from ta.volatility import BollingerBands, AverageTrueRange\n",
    "    from ta.trend import ADXIndicator, MACD, CCIIndicator\n",
    "    from ta.momentum import StochasticOscillator, ROCIndicator, RSIIndicator\n",
    "    TA_AVAILABLE = True\n",
    "    print(\"‚úÖ Technical analysis library loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Technical analysis library import failed: {e}\")\n",
    "    TA_AVAILABLE = False\n",
    "\n",
    "# Data sources with fallbacks\n",
    "YFINANCE_AVAILABLE = False\n",
    "METATRADER_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    YFINANCE_AVAILABLE = True\n",
    "    print(\"‚úÖ Yahoo Finance available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Yahoo Finance not available\")\n",
    "\n",
    "try:\n",
    "    # Try to import local modules with fallback\n",
    "    from src.data.loader import load_or_fetch, load_metatrader_data\n",
    "    METATRADER_AVAILABLE = True\n",
    "    print(\"‚úÖ MetaTrader 5 loader available\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è MetaTrader 5 loader not available - using fallbacks\")\n",
    "    \n",
    "    # Fallback implementations\n",
    "    def load_or_fetch(*args, **kwargs):\n",
    "        raise NotImplementedError(\"MetaTrader loader not available\")\n",
    "    \n",
    "    def load_metatrader_data(*args, **kwargs):\n",
    "        raise NotImplementedError(\"MetaTrader loader not available\")\n",
    "\n",
    "# Check critical dependencies\n",
    "if not TF_AVAILABLE:\n",
    "    raise ImportError(\"TensorFlow is required but not available. Please install: pip install tensorflow\")\n",
    "\n",
    "if not TA_AVAILABLE:\n",
    "    raise ImportError(\"Technical analysis library is required. Please install: pip install ta\")\n",
    "\n",
    "if not YFINANCE_AVAILABLE and not METATRADER_AVAILABLE:\n",
    "    raise ImportError(\"No data source available. Please install: pip install yfinance\")\n",
    "\n",
    "print(\"\\n‚úÖ All critical libraries imported successfully\")\n",
    "print(f\"Available data sources: Yahoo Finance: {YFINANCE_AVAILABLE}, MetaTrader: {METATRADER_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Validation and Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_data_quality(df, symbol):\n",
    "    \"\"\"\n",
    "    Validate data quality and report issues.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame to validate\n",
    "        symbol: Symbol name for logging\n",
    "    \n",
    "    Returns:\n",
    "        list: List of issues found\n",
    "    \"\"\"\n",
    "    issues = []\n",
    "    \n",
    "    if df.empty:\n",
    "        issues.append(\"DataFrame is empty\")\n",
    "        return issues\n",
    "    \n",
    "    # Check for minimum data points\n",
    "    if len(df) < MIN_DATA_POINTS:\n",
    "        issues.append(f\"Insufficient data: {len(df)} rows, need at least {MIN_DATA_POINTS}\")\n",
    "    \n",
    "    # Check for NaN values\n",
    "    nan_counts = df.isnull().sum()\n",
    "    total_cells = len(df) * len(df.columns)\n",
    "    nan_ratio = nan_counts.sum() / total_cells\n",
    "    \n",
    "    if nan_ratio > MAX_NAN_RATIO:\n",
    "        issues.append(f\"High NaN ratio: {nan_ratio:.2%} > {MAX_NAN_RATIO:.2%}\")\n",
    "    \n",
    "    if nan_counts.any():\n",
    "        issues.append(f\"NaN values found: {nan_counts[nan_counts > 0].to_dict()}\")\n",
    "    \n",
    "    # Check for duplicate timestamps\n",
    "    if df.index.duplicated().any():\n",
    "        issues.append(\"Duplicate timestamps found\")\n",
    "    \n",
    "    # Check for OHLC data if available\n",
    "    price_cols = ['open', 'high', 'low', 'close']\n",
    "    available_price_cols = [col for col in price_cols if col in df.columns]\n",
    "    \n",
    "    if available_price_cols:\n",
    "        # Check for non-positive values\n",
    "        for col in available_price_cols:\n",
    "            if (df[col] <= 0).any():\n",
    "                issues.append(f\"Non-positive values in {col}\")\n",
    "        \n",
    "        # Check OHLC logic if all available\n",
    "        if all(col in df.columns for col in price_cols):\n",
    "            if (df['high'] < df['low']).any():\n",
    "                issues.append(\"High < Low detected\")\n",
    "            if (df['high'] < df['open']).any() or (df['high'] < df['close']).any():\n",
    "                issues.append(\"High < Open/Close detected\")\n",
    "            if (df['low'] > df['open']).any() or (df['low'] > df['close']).any():\n",
    "                issues.append(\"Low > Open/Close detected\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "def clean_data(df, symbol):\n",
    "    \"\"\"\n",
    "    Clean and standardize data.\n",
    "    \n",
    "    Args:\n",
    "        df: Raw DataFrame\n",
    "        symbol: Symbol name\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Cleaned DataFrame\n",
    "    \"\"\"\n",
    "    logger.info(f\"Cleaning data for {symbol}...\")\n",
    "    \n",
    "    # Remove duplicates\n",
    "    df = df[~df.index.duplicated(keep='first')]\n",
    "    \n",
    "    # Sort by index\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    # Remove rows with all NaN values\n",
    "    df = df.dropna(how='all')\n",
    "    \n",
    "    # Forward fill and backward fill reasonable amounts\n",
    "    df = df.ffill(limit=3).bfill(limit=3)\n",
    "    \n",
    "    # Remove remaining NaN rows\n",
    "    initial_len = len(df)\n",
    "    df = df.dropna()\n",
    "    final_len = len(df)\n",
    "    \n",
    "    if initial_len != final_len:\n",
    "        logger.warning(f\"{symbol}: Removed {initial_len - final_len} rows with NaN values\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"\n",
    "    Clear memory and run garbage collection.\n",
    "    \"\"\"\n",
    "    gc.collect()\n",
    "    if TF_AVAILABLE:\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "print(\"‚úÖ Data validation functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Robust Data Loading with Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yahoo_finance_data(symbol, period=\"2y\", interval=\"1h\"):\n",
    "    \"\"\"\n",
    "    Load data from Yahoo Finance with proper error handling.\n",
    "    \n",
    "    Args:\n",
    "        symbol: Trading symbol\n",
    "        period: Data period\n",
    "        interval: Data interval\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: OHLC data\n",
    "    \"\"\"\n",
    "    if not YFINANCE_AVAILABLE:\n",
    "        raise ImportError(\"Yahoo Finance not available\")\n",
    "    \n",
    "    # Format symbol for Yahoo Finance\n",
    "    if len(symbol) == 6 and symbol.isalpha():  # Forex pair like EURUSD\n",
    "        ticker = f\"{symbol}=X\"\n",
    "    else:\n",
    "        ticker = symbol\n",
    "    \n",
    "    logger.info(f\"Loading {symbol} from Yahoo Finance as {ticker}...\")\n",
    "    \n",
    "    try:\n",
    "        df = yf.download(ticker, period=period, interval=interval, progress=False)\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No data received for {ticker}\")\n",
    "        \n",
    "        # Reset index to get datetime as column\n",
    "        df = df.reset_index()\n",
    "        \n",
    "        # Standardize column names\n",
    "        column_mapping = {\n",
    "            'Datetime': 'time',\n",
    "            'Date': 'time',\n",
    "            'Open': 'open',\n",
    "            'High': 'high', \n",
    "            'Low': 'low',\n",
    "            'Close': 'close',\n",
    "            'Volume': 'volume',\n",
    "            'Adj Close': 'adj_close'\n",
    "        }\n",
    "        \n",
    "        df = df.rename(columns=column_mapping)\n",
    "        \n",
    "        # Ensure required columns exist\n",
    "        required_cols = ['time', 'open', 'high', 'low', 'close']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Add volume if missing\n",
    "        if 'volume' not in df.columns:\n",
    "            df['volume'] = 0\n",
    "            logger.warning(f\"Volume data not available for {symbol}, using zeros\")\n",
    "        \n",
    "        df['tick_volume'] = df['volume']\n",
    "        \n",
    "        # Convert time and set as index\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df = df.set_index('time')\n",
    "        \n",
    "        # Clean the data\n",
    "        df = clean_data(df, symbol)\n",
    "        \n",
    "        # Validate data quality\n",
    "        issues = validate_data_quality(df, symbol)\n",
    "        if issues:\n",
    "            logger.warning(f\"Data quality issues for {symbol}: {issues}\")\n",
    "            if any(\"Insufficient data\" in issue for issue in issues):\n",
    "                raise ValueError(f\"Data quality issues: {issues}\")\n",
    "        \n",
    "        logger.info(f\"‚úÖ Successfully loaded {len(df)} records for {symbol}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load {symbol} from Yahoo Finance: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_metatrader_data_safe(symbol, broker=\"amp_global\", interval=\"H1\"):\n",
    "    \"\"\"\n",
    "    Safely load MetaTrader data with error handling.\n",
    "    \n",
    "    Args:\n",
    "        symbol: Trading symbol\n",
    "        broker: Broker name\n",
    "        interval: Time interval\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: OHLC data\n",
    "    \"\"\"\n",
    "    if not METATRADER_AVAILABLE:\n",
    "        raise ImportError(\"MetaTrader loader not available\")\n",
    "    \n",
    "    logger.info(f\"Loading {symbol} from MetaTrader...\")\n",
    "    \n",
    "    try:\n",
    "        df = load_or_fetch(\n",
    "            symbol=symbol,\n",
    "            provider=\"metatrader\",\n",
    "            loader_func=load_metatrader_data,\n",
    "            api_key=\"\",\n",
    "            interval=interval,\n",
    "            broker=broker\n",
    "        )\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No data received for {symbol}\")\n",
    "        \n",
    "        # Standardize columns\n",
    "        required_cols = ['time', 'open', 'high', 'low', 'close']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Ensure volume column\n",
    "        volume_col = 'tick_volume' if 'tick_volume' in df.columns else 'volume'\n",
    "        if volume_col not in df.columns:\n",
    "            df['tick_volume'] = 0\n",
    "        else:\n",
    "            df['tick_volume'] = df[volume_col]\n",
    "        \n",
    "        # Convert time and set index\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df = df.set_index('time')\n",
    "        \n",
    "        # Clean the data\n",
    "        df = clean_data(df, symbol)\n",
    "        \n",
    "        logger.info(f\"‚úÖ Successfully loaded {len(df)} records for {symbol}\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load {symbol} from MetaTrader: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def load_forex_data(symbols, provider=\"yahoo\", broker=\"amp_global\", interval=\"H1\"):\n",
    "    \"\"\"\n",
    "    Load forex data for multiple symbols with robust error handling.\n",
    "    \n",
    "    Args:\n",
    "        symbols: List of symbol names\n",
    "        provider: Data provider ('metatrader' or 'yahoo')\n",
    "        broker: Broker name for MetaTrader\n",
    "        interval: Time interval\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: MultiIndex DataFrame with (symbol, field) columns\n",
    "    \"\"\"\n",
    "    logger.info(f\"Loading data for {len(symbols)} symbols using {provider}...\")\n",
    "    \n",
    "    data = {}\n",
    "    successful_loads = 0\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        logger.info(f\"üì• Loading data for {symbol}...\")\n",
    "        \n",
    "        df = None\n",
    "        \n",
    "        # Try primary provider first\n",
    "        try:\n",
    "            if provider == \"metatrader\" and METATRADER_AVAILABLE:\n",
    "                df = load_metatrader_data_safe(symbol, broker, interval)\n",
    "            elif provider == \"yahoo\" and YFINANCE_AVAILABLE:\n",
    "                df = load_yahoo_finance_data(symbol)\n",
    "            else:\n",
    "                raise ValueError(f\"Provider {provider} not available\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Primary provider failed for {symbol}: {str(e)}\")\n",
    "            \n",
    "            # Try fallback provider\n",
    "            try:\n",
    "                if provider != \"yahoo\" and YFINANCE_AVAILABLE:\n",
    "                    logger.info(f\"Trying Yahoo Finance fallback for {symbol}...\")\n",
    "                    df = load_yahoo_finance_data(symbol)\n",
    "                elif provider != \"metatrader\" and METATRADER_AVAILABLE:\n",
    "                    logger.info(f\"Trying MetaTrader fallback for {symbol}...\")\n",
    "                    df = load_metatrader_data_safe(symbol, broker, interval)\n",
    "                else:\n",
    "                    logger.error(f\"No fallback available for {symbol}\")\n",
    "                    continue\n",
    "                    \n",
    "            except Exception as e2:\n",
    "                logger.error(f\"All providers failed for {symbol}: {str(e2)}\")\n",
    "                continue\n",
    "        \n",
    "        # If we successfully loaded data\n",
    "        if df is not None and not df.empty:\n",
    "            # Add to MultiIndex structure\n",
    "            for col in ['open', 'high', 'low', 'close', 'tick_volume']:\n",
    "                if col in df.columns:\n",
    "                    data[(symbol, col)] = df[col]\n",
    "            \n",
    "            successful_loads += 1\n",
    "            logger.info(f\"‚úÖ Successfully loaded {len(df)} records for {symbol}\")\n",
    "        else:\n",
    "            logger.error(f\"‚ùå Failed to load any data for {symbol}\")\n",
    "    \n",
    "    if successful_loads == 0:\n",
    "        raise ValueError(\"No data loaded successfully for any symbol\")\n",
    "    \n",
    "    if successful_loads < len(symbols):\n",
    "        logger.warning(f\"Only loaded {successful_loads}/{len(symbols)} symbols successfully\")\n",
    "    \n",
    "    prices_df = pd.DataFrame(data)\n",
    "    \n",
    "    if prices_df.empty:\n",
    "        raise ValueError(\"Final dataset is empty\")\n",
    "    \n",
    "    logger.info(f\"\\nüìä Final dataset shape: {prices_df.shape}\")\n",
    "    logger.info(f\"Date range: {prices_df.index.min()} to {prices_df.index.max()}\")\n",
    "    logger.info(f\"Successful symbols: {[col[0] for col in prices_df.columns[::5]]}\")\n",
    "    \n",
    "    return prices_df\n",
    "\n",
    "print(\"‚úÖ Robust data loading functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Data with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data for all symbols with comprehensive error handling\n",
    "try:\n",
    "    logger.info(\"üîÑ Starting data loading process...\")\n",
    "    \n",
    "    prices = load_forex_data(\n",
    "        symbols=ALL_SYMBOLS,\n",
    "        provider=PROVIDER,\n",
    "        broker=BROKER,\n",
    "        interval=INTERVAL\n",
    "    )\n",
    "    \n",
    "    logger.info(\"‚úÖ Data loading completed successfully\")\n",
    "    \n",
    "    # Display sample data\n",
    "    print(\"\\nüìà Sample data (first 5 rows):\")\n",
    "    print(prices.head())\n",
    "    \n",
    "    print(\"\\nüìä Data summary:\")\n",
    "    print(f\"Shape: {prices.shape}\")\n",
    "    print(f\"Date range: {prices.index.min()} to {prices.index.max()}\")\n",
    "    print(f\"Available symbols: {list(set([col[0] for col in prices.columns]))}\")\n",
    "    \n",
    "    # Check data availability for target symbols\n",
    "    available_target_symbols = []\n",
    "    for symbol in SYMBOLS:\n",
    "        if (symbol, 'close') in prices.columns:\n",
    "            available_target_symbols.append(symbol)\n",
    "            data_points = prices[(symbol, 'close')].count()\n",
    "            print(f\"  {symbol}: {data_points} data points\")\n",
    "    \n",
    "    if not available_target_symbols:\n",
    "        raise ValueError(f\"None of the target symbols {SYMBOLS} are available in loaded data\")\n",
    "    \n",
    "    SYMBOLS = available_target_symbols  # Update to only available symbols\n",
    "    logger.info(f\"Updated target symbols to available ones: {SYMBOLS}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Data loading failed: {str(e)}\")\n",
    "    print(f\"\\n‚ùå Data loading failed: {str(e)}\")\n",
    "    print(\"\\nPlease check:\")\n",
    "    print(\"1. Internet connection\")\n",
    "    print(\"2. Symbol names are correct\")\n",
    "    print(\"3. Required packages are installed (yfinance, ta)\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering with Robust Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def calculate_relative_currency_strength(prices_df):\n    \"\"\"\n    Calculate Relative Currency Strength (RCS) with robust error handling.\n    \n    Args:\n        prices_df: MultiIndex DataFrame with (symbol, 'close') columns\n    \n    Returns:\n        pandas.DataFrame: RCS values for each currency\n    \"\"\"\n    logger.info(\"üßÆ Calculating Relative Currency Strength...\")\n    \n    try:\n        # Extract available close prices only\n        close_prices = {}\n        available_symbols = []\n        \n        for col in prices_df.columns:\n            if len(col) == 2 and col[1] == 'close':  # (symbol, 'close')\n                symbol = col[0]\n                if len(symbol) == 6 and symbol.isalpha():  # Valid forex pair\n                    available_symbols.append(symbol)\n                    close_prices[symbol] = prices_df[col]\n        \n        if not close_prices:\n            raise ValueError(\"No valid close price data available for RCS calculation\")\n        \n        logger.info(f\"Calculating RCS for symbols: {available_symbols}\")\n        \n        close_df = pd.DataFrame(close_prices)\n        log_returns = np.log(close_df / close_df.shift(1)).dropna()\n        \n        if log_returns.empty:\n            raise ValueError(\"No valid log returns calculated\")\n        \n        # Extract unique currencies from available symbols\n        currencies = list(set([s[:3] for s in available_symbols] + [s[3:6] for s in available_symbols]))\n        currencies = [c for c in currencies if len(c) == 3 and c.isalpha()]\n        \n        logger.info(f\"Identified currencies: {currencies}\")\n        \n        # Calculate RCS\n        rcs_data = {c: [] for c in currencies}\n        \n        for i in range(len(log_returns)):\n            row = log_returns.iloc[i]\n            daily_strength = {c: 0 for c in currencies}\n            counts = {c: 0 for c in currencies}\n            \n            for pair, ret in row.items():\n                if pd.notna(ret) and len(pair) == 6:\n                    base, quote = pair[:3], pair[3:]\n                    if base in daily_strength and quote in daily_strength:\n                        daily_strength[base] += ret\n                        daily_strength[quote] -= ret\n                        counts[base] += 1\n                        counts[quote] += 1\n            \n            for c in currencies:\n                avg_strength = daily_strength[c] / counts[c] if counts[c] > 0 else 0\n                rcs_data[c].append(avg_strength)\n        \n        rcs_df = pd.DataFrame(rcs_data, index=log_returns.index)\n        \n        # Validate RCS data\n        if rcs_df.empty:\n            raise ValueError(\"RCS calculation resulted in empty DataFrame\")\n        \n        # Check for excessive NaN values\n        nan_ratio = rcs_df.isnull().sum().sum() / (len(rcs_df) * len(rcs_df.columns))\n        if nan_ratio > MAX_NAN_RATIO:\n            logger.warning(f\"High NaN ratio in RCS data: {nan_ratio:.2%}\")\n        \n        # Clean RCS data using modern pandas methods\n        rcs_df = rcs_df.ffill().bfill().fillna(0)\n        \n        logger.info(f\"‚úÖ RCS calculated successfully for {len(currencies)} currencies\")\n        logger.info(f\"RCS data shape: {rcs_df.shape}\")\n        \n        return rcs_df\n        \n    except Exception as e:\n        logger.error(f\"RCS calculation failed: {str(e)}\")\n        # Return empty DataFrame with proper structure\n        return pd.DataFrame()\n\ndef calculate_technical_indicators(prices_df, symbol):\n    \"\"\"\n    Calculate technical indicators with comprehensive error handling.\n    \n    Args:\n        prices_df: MultiIndex DataFrame with OHLC data\n        symbol: Symbol name\n    \n    Returns:\n        pandas.DataFrame: Technical indicators\n    \"\"\"\n    logger.info(f\"üìä Calculating technical indicators for {symbol}...\")\n    \n    try:\n        # Extract OHLC data with fallbacks\n        ohlc_data = {}\n        for field in ['open', 'high', 'low', 'close']:\n            if (symbol, field) in prices_df.columns:\n                ohlc_data[field] = prices_df[(symbol, field)]\n            elif (symbol, 'close') in prices_df.columns:\n                # Fallback to close price if field missing\n                ohlc_data[field] = prices_df[(symbol, 'close')]\n                if field != 'close':\n                    logger.warning(f\"Using close price as fallback for {field} in {symbol}\")\n            else:\n                raise ValueError(f\"No price data available for {symbol}\")\n        \n        close = ohlc_data['close'].dropna()\n        high = ohlc_data['high'].dropna()\n        low = ohlc_data['low'].dropna()\n        \n        if len(close) < 50:  # Need minimum data for indicators\n            raise ValueError(f\"Insufficient data for {symbol}: only {len(close)} points\")\n        \n        indicators = pd.DataFrame(index=close.index)\n        \n        # Momentum indicators with error handling\n        try:\n            indicators['rsi'] = RSIIndicator(close=close, window=14).rsi()\n        except Exception as e:\n            logger.warning(f\"RSI calculation failed for {symbol}: {e}\")\n            indicators['rsi'] = 50  # Neutral RSI\n        \n        try:\n            indicators['roc'] = ROCIndicator(close=close, window=10).roc()\n        except Exception as e:\n            logger.warning(f\"ROC calculation failed for {symbol}: {e}\")\n            indicators['roc'] = 0\n        \n        indicators['momentum'] = close.pct_change(periods=10).fillna(0)\n        \n        # Trend indicators\n        try:\n            macd = MACD(close=close)\n            indicators['macd'] = macd.macd()\n            indicators['macd_signal'] = macd.macd_signal()\n            indicators['macd_histogram'] = macd.macd_diff()\n        except Exception as e:\n            logger.warning(f\"MACD calculation failed for {symbol}: {e}\")\n            indicators['macd'] = 0\n            indicators['macd_signal'] = 0\n            indicators['macd_histogram'] = 0\n        \n        try:\n            indicators['cci'] = CCIIndicator(high=high, low=low, close=close).cci()\n        except Exception as e:\n            logger.warning(f\"CCI calculation failed for {symbol}: {e}\")\n            indicators['cci'] = 0\n        \n        try:\n            indicators['adx'] = ADXIndicator(high=high, low=low, close=close).adx()\n        except Exception as e:\n            logger.warning(f\"ADX calculation failed for {symbol}: {e}\")\n            indicators['adx'] = 25  # Neutral ADX\n        \n        # Volatility indicators\n        try:\n            indicators['atr'] = AverageTrueRange(high=high, low=low, close=close).average_true_range()\n        except Exception as e:\n            logger.warning(f\"ATR calculation failed for {symbol}: {e}\")\n            indicators['atr'] = close.rolling(20).std().fillna(0)\n        \n        try:\n            bb = BollingerBands(close=close)\n            indicators['bb_upper'] = bb.bollinger_hband()\n            indicators['bb_lower'] = bb.bollinger_lband()\n            indicators['bb_width'] = (bb.bollinger_hband() - bb.bollinger_lband()) / bb.bollinger_mavg()\n            indicators['bb_position'] = (close - bb.bollinger_lband()) / (bb.bollinger_hband() - bb.bollinger_lband())\n        except Exception as e:\n            logger.warning(f\"Bollinger Bands calculation failed for {symbol}: {e}\")\n            sma = close.rolling(20).mean()\n            std = close.rolling(20).std()\n            indicators['bb_upper'] = sma + 2 * std\n            indicators['bb_lower'] = sma - 2 * std\n            indicators['bb_width'] = (2 * std) / sma\n            indicators['bb_position'] = 0.5\n        \n        # Stochastic oscillator\n        try:\n            stoch = StochasticOscillator(high=high, low=low, close=close)\n            indicators['stoch_k'] = stoch.stoch()\n            indicators['stoch_d'] = stoch.stoch_signal()\n        except Exception as e:\n            logger.warning(f\"Stochastic calculation failed for {symbol}: {e}\")\n            indicators['stoch_k'] = 50\n            indicators['stoch_d'] = 50\n        \n        # Price-based features\n        indicators['return_1h'] = close.pct_change(1).fillna(0)\n        indicators['return_4h'] = close.pct_change(4).fillna(0)\n        indicators['return_24h'] = close.pct_change(24).fillna(0)\n        \n        # Rolling statistics\n        indicators['sma_5'] = close.rolling(window=5).mean()\n        indicators['sma_20'] = close.rolling(window=20).mean()\n        indicators['ema_12'] = close.ewm(span=12).mean()\n        indicators['ema_26'] = close.ewm(span=26).mean()\n        \n        indicators['volatility_5'] = close.rolling(window=5).std()\n        indicators['volatility_20'] = close.rolling(window=20).std()\n        \n        # Price position indicators\n        rolling_min_5 = close.rolling(5).min()\n        rolling_max_5 = close.rolling(5).max()\n        indicators['price_position_5'] = ((close - rolling_min_5) / \n                                        (rolling_max_5 - rolling_min_5).replace(0, np.nan)).fillna(0.5)\n        \n        rolling_min_20 = close.rolling(20).min()\n        rolling_max_20 = close.rolling(20).max()\n        indicators['price_position_20'] = ((close - rolling_min_20) / \n                                         (rolling_max_20 - rolling_min_20).replace(0, np.nan)).fillna(0.5)\n        \n        # Time-based features\n        indicators['hour'] = indicators.index.hour\n        indicators['day_of_week'] = indicators.index.dayofweek\n        indicators['month'] = indicators.index.month\n        \n        # Clean indicators data using modern pandas methods\n        indicators = indicators.ffill().bfill()\n        \n        # Replace any remaining infinite values\n        indicators = indicators.replace([np.inf, -np.inf], np.nan).fillna(0)\n        \n        logger.info(f\"‚úÖ Calculated {len(indicators.columns)} technical indicators for {symbol}\")\n        logger.info(f\"Indicators data shape: {indicators.shape}\")\n        \n        return indicators\n        \n    except Exception as e:\n        logger.error(f\"Technical indicators calculation failed for {symbol}: {str(e)}\")\n        raise\n\nprint(\"‚úÖ Feature engineering functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Calculate RCS\n",
    "    logger.info(\"Starting RCS calculation...\")\n",
    "    rcs = calculate_relative_currency_strength(prices)\n",
    "    \n",
    "    if rcs.empty:\n",
    "        logger.warning(\"RCS calculation failed, proceeding without RCS features\")\n",
    "        rcs = pd.DataFrame()  # Empty RCS for fallback\n",
    "    else:\n",
    "        logger.info(f\"‚úÖ RCS calculated successfully: {rcs.shape}\")\n",
    "    \n",
    "    # Calculate technical indicators for target symbols\n",
    "    all_features = {}\n",
    "    \n",
    "    for symbol in SYMBOLS:\n",
    "        if (symbol, 'close') in prices.columns:\n",
    "            try:\n",
    "                logger.info(f\"Calculating indicators for {symbol}...\")\n",
    "                indicators = calculate_technical_indicators(prices, symbol)\n",
    "                all_features[symbol] = indicators\n",
    "                logger.info(f\"üìä {symbol}: {indicators.shape[0]} rows, {indicators.shape[1]} features\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to calculate indicators for {symbol}: {str(e)}\")\n",
    "                continue\n",
    "        else:\n",
    "            logger.warning(f\"No close price data available for {symbol}\")\n",
    "    \n",
    "    if not all_features:\n",
    "        raise ValueError(\"No technical indicators calculated for any symbol\")\n",
    "    \n",
    "    # Update SYMBOLS to only include successfully processed ones\n",
    "    SYMBOLS = list(all_features.keys())\n",
    "    logger.info(f\"Successfully processed symbols: {SYMBOLS}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Feature engineering completed successfully\")\n",
    "    \n",
    "    # Display feature summary\n",
    "    for symbol in SYMBOLS:\n",
    "        features = all_features[symbol]\n",
    "        print(f\"\\n{symbol} features:\")\n",
    "        print(f\"  Shape: {features.shape}\")\n",
    "        print(f\"  Date range: {features.index.min()} to {features.index.max()}\")\n",
    "        print(f\"  Sample features: {list(features.columns[:5])}...\")\n",
    "        \n",
    "        # Check data quality\n",
    "        nan_count = features.isnull().sum().sum()\n",
    "        if nan_count > 0:\n",
    "            print(f\"  ‚ö†Ô∏è NaN values: {nan_count}\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ No NaN values\")\n",
    "    \n",
    "    if not rcs.empty:\n",
    "        print(f\"\\nRCS features: {list(rcs.columns)}\")\n",
    "        print(f\"RCS shape: {rcs.shape}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è RCS features not available - proceeding with technical indicators only\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Feature engineering failed: {str(e)}\")\n",
    "    print(f\"\\n‚ùå Feature engineering failed: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Target Variable Creation and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "def create_target_variable(prices_df, symbol, prediction_horizon=1):\n    \"\"\"\n    Create binary target variable for price direction prediction with validation.\n    \n    Args:\n        prices_df: MultiIndex DataFrame with price data\n        symbol: Symbol name\n        prediction_horizon: Number of periods ahead to predict\n    \n    Returns:\n        pandas.Series: Binary target (1 = price up, 0 = price down)\n    \"\"\"\n    logger.info(f\"Creating target variable for {symbol}...\")\n    \n    try:\n        if (symbol, 'close') not in prices_df.columns:\n            raise ValueError(f\"No close price data for {symbol}\")\n        \n        close_prices = prices_df[(symbol, 'close')].dropna()\n        \n        if len(close_prices) < prediction_horizon + 1:\n            raise ValueError(f\"Insufficient data for target creation: {len(close_prices)} points\")\n        \n        future_prices = close_prices.shift(-prediction_horizon)\n        target = (future_prices > close_prices).astype(int)\n        \n        # Remove NaN values\n        target = target.dropna()\n        \n        if target.empty:\n            raise ValueError(\"Target variable is empty after processing\")\n        \n        # Check class balance\n        class_counts = target.value_counts()\n        if len(class_counts) < 2:\n            raise ValueError(f\"Target has only one class: {class_counts.index[0]}\")\n        \n        class_balance = class_counts.min() / class_counts.sum()\n        logger.info(f\"Target class balance for {symbol}: {class_balance:.2%} minority class\")\n        \n        if class_balance < 0.05:\n            logger.warning(f\"Severe class imbalance detected for {symbol}: {class_counts.to_dict()}\")\n        \n        target.name = symbol\n        logger.info(f\"‚úÖ Target created for {symbol}: {len(target)} samples\")\n        \n        return target\n        \n    except Exception as e:\n        logger.error(f\"Target creation failed for {symbol}: {str(e)}\")\n        raise\n\ndef prepare_features_and_target(indicators_df, rcs_df, target_series, lookback_window):\n    \"\"\"\n    Prepare feature matrix and target with comprehensive validation.\n    \n    Args:\n        indicators_df: Technical indicators DataFrame\n        rcs_df: Relative Currency Strength DataFrame\n        target_series: Target variable Series\n        lookback_window: Number of time steps for sequences\n    \n    Returns:\n        tuple: (X, y, feature_names, scaler)\n    \"\"\"\n    logger.info(f\"üîß Preparing features and target for {target_series.name}...\")\n    \n    try:\n        # Validate inputs\n        if indicators_df.empty:\n            raise ValueError(\"Indicators DataFrame is empty\")\n        \n        if len(indicators_df) < lookback_window * 2:\n            raise ValueError(f\"Insufficient indicator data: {len(indicators_df)} rows, need at least {lookback_window * 2}\")\n        \n        if target_series.empty:\n            raise ValueError(\"Target series is empty\")\n        \n        # Start with indicators as base features\n        combined_features = indicators_df.copy()\n        \n        # Add RCS features if available\n        if not rcs_df.empty:\n            # Align indices first\n            common_rcs_index = indicators_df.index.intersection(rcs_df.index)\n            \n            if len(common_rcs_index) > lookback_window:\n                # Add available RCS features\n                available_currencies = [col for col in rcs_df.columns \n                                      if col in ['USD', 'EUR', 'GBP', 'JPY', 'AUD', 'CAD', 'CHF', 'NZD']]\n                \n                for currency in available_currencies:\n                    if currency in rcs_df.columns:\n                        rcs_feature_name = f'rcs_{currency}'\n                        # Align RCS data with indicators\n                        aligned_rcs = rcs_df[currency].reindex(indicators_df.index)\n                        combined_features[rcs_feature_name] = aligned_rcs\n                \n                logger.info(f\"Added {len(available_currencies)} RCS features\")\n            else:\n                logger.warning(\"Insufficient RCS data overlap, skipping RCS features\")\n        else:\n            logger.info(\"No RCS data available, using only technical indicators\")\n        \n        # Align with target\n        common_index = combined_features.index.intersection(target_series.index)\n        \n        if len(common_index) < lookback_window * 2:\n            raise ValueError(f\"Insufficient aligned data: {len(common_index)} points, need at least {lookback_window * 2}\")\n        \n        # Select aligned data\n        X_df = combined_features.loc[common_index].copy()\n        y_series = target_series.loc[common_index].copy()\n        \n        # Clean features data\n        logger.info(f\"Cleaning features data...\")\n        \n        # Forward fill and backward fill using modern pandas methods\n        X_df = X_df.ffill(limit=5).bfill(limit=5)\n        \n        # Replace infinite values\n        X_df = X_df.replace([np.inf, -np.inf], np.nan)\n        \n        # Drop columns with too many NaN values\n        nan_threshold = len(X_df) * MAX_NAN_RATIO\n        X_df = X_df.dropna(axis=1, thresh=len(X_df) - nan_threshold)\n        \n        # Drop rows with any remaining NaN values\n        initial_rows = len(X_df)\n        X_df = X_df.dropna()\n        y_series = y_series.loc[X_df.index]\n        \n        if len(X_df) != initial_rows:\n            logger.warning(f\"Removed {initial_rows - len(X_df)} rows with NaN values\")\n        \n        if len(X_df) < lookback_window:\n            raise ValueError(f\"After cleaning, insufficient data: {len(X_df)} rows\")\n        \n        logger.info(f\"Final aligned data: {len(X_df)} rows, {len(X_df.columns)} features\")\n        \n        # Scale features\n        logger.info(\"Scaling features...\")\n        scaler = StandardScaler()\n        \n        try:\n            X_scaled = scaler.fit_transform(X_df)\n        except Exception as e:\n            logger.error(f\"Feature scaling failed: {str(e)}\")\n            # Try robust scaling as fallback\n            from sklearn.preprocessing import RobustScaler\n            scaler = RobustScaler()\n            X_scaled = scaler.fit_transform(X_df)\n            logger.info(\"Used RobustScaler as fallback\")\n        \n        # Create sequences for LSTM\n        logger.info(f\"Creating sequences with lookback window: {lookback_window}...\")\n        \n        X_sequences = []\n        y_sequences = []\n        \n        for i in range(lookback_window, len(X_scaled)):\n            X_sequences.append(X_scaled[i-lookback_window:i])\n            y_sequences.append(y_series.iloc[i])\n        \n        if len(X_sequences) == 0:\n            raise ValueError(\"No sequences created - check data length and lookback window\")\n        \n        X = np.array(X_sequences)\n        y = np.array(y_sequences)\n        \n        feature_names = X_df.columns.tolist()\n        \n        # Final validation\n        if X.shape[0] < MIN_TRAINING_SAMPLES:\n            raise ValueError(f\"Insufficient sequences for training: {X.shape[0]}, need at least {MIN_TRAINING_SAMPLES}\")\n        \n        # Check for feature variance\n        feature_vars = np.var(X_scaled, axis=0)\n        zero_var_features = np.sum(feature_vars == 0)\n        if zero_var_features > 0:\n            logger.warning(f\"Found {zero_var_features} features with zero variance\")\n        \n        logger.info(f\"‚úÖ Prepared sequences successfully:\")\n        logger.info(f\"  X shape: {X.shape}\")\n        logger.info(f\"  y shape: {y.shape}\")\n        logger.info(f\"  Features: {len(feature_names)}\")\n        \n        return X, y, feature_names, scaler\n        \n    except Exception as e:\n        logger.error(f\"Feature preparation failed: {str(e)}\")\n        raise\n\nprint(\"‚úÖ Data preparation functions defined\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Prepare Data for All Symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for each target symbol\n",
    "prepared_data = {}\n",
    "successful_preparations = 0\n",
    "\n",
    "for symbol in SYMBOLS:\n",
    "    try:\n",
    "        logger.info(f\"\\nüéØ Preparing data for {symbol}...\")\n",
    "        \n",
    "        if symbol not in all_features:\n",
    "            logger.warning(f\"No features available for {symbol}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        if (symbol, 'close') not in prices.columns:\n",
    "            logger.warning(f\"No price data available for {symbol}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Create target\n",
    "        target = create_target_variable(prices, symbol)\n",
    "        \n",
    "        # Prepare features\n",
    "        X, y, feature_names, scaler = prepare_features_and_target(\n",
    "            all_features[symbol], rcs, target, LOOKBACK_WINDOW\n",
    "        )\n",
    "        \n",
    "        prepared_data[symbol] = {\n",
    "            'X': X,\n",
    "            'y': y,\n",
    "            'feature_names': feature_names,\n",
    "            'scaler': scaler,\n",
    "            'target_distribution': pd.Series(y).value_counts(normalize=True)\n",
    "        }\n",
    "        \n",
    "        successful_preparations += 1\n",
    "        \n",
    "        logger.info(f\"‚úÖ {symbol} data preparation completed\")\n",
    "        print(f\"\\nüìä {symbol} Summary:\")\n",
    "        print(f\"  Sequences: {X.shape[0]}\")\n",
    "        print(f\"  Timesteps: {X.shape[1]}\")\n",
    "        print(f\"  Features: {X.shape[2]}\")\n",
    "        print(f\"  Target distribution:\")\n",
    "        for class_val, prob in prepared_data[symbol]['target_distribution'].items():\n",
    "            print(f\"    Class {class_val}: {prob:.2%}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Data preparation failed for {symbol}: {str(e)}\")\n",
    "        print(f\"‚ùå Failed to prepare data for {symbol}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "if successful_preparations == 0:\n",
    "    raise ValueError(\"No symbols successfully prepared for training\")\n",
    "\n",
    "# Update SYMBOLS to only successfully prepared ones\n",
    "SYMBOLS = list(prepared_data.keys())\n",
    "\n",
    "logger.info(f\"\\n‚úÖ Data preparation completed for {successful_preparations} symbols: {SYMBOLS}\")\n",
    "print(f\"\\nüéâ Successfully prepared data for {successful_preparations} symbols: {SYMBOLS}\")\n",
    "\n",
    "# Clear memory\n",
    "clear_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}