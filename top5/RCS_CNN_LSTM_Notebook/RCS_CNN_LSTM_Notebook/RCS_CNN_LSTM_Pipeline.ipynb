{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCS CNN+LSTM Pipeline (MetaTrader 5, Modular, Broker-Aware)\n",
    "\n",
    "This notebook demonstrates a robust, modular pipeline for FX prediction using MetaTrader 5 data, advanced feature engineering, deep learning, and feature set analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Data Loading ---\n",
    "from async_data_loader import load_or_fetch, load_metatrader_data\n",
    "import pandas as pd\n",
    "\n",
    "symbols = [\"EURUSD\", \"GBPUSD\", \"USDJPY\", \"AUDUSD\", \"USDCAD\", \"EURJPY\", \"GBPJPY\"]\n",
    "provider = \"metatrader\"\n",
    "broker = \"amp_global\"\n",
    "interval = \"H1\"\n",
    "\n",
    "data = {}\n",
    "for sym in symbols:\n",
    "    df = load_or_fetch(\n",
    "        symbol=sym,\n",
    "        provider=provider,\n",
    "        loader_func=load_metatrader_data,\n",
    "        api_key=\"\",\n",
    "        interval=interval,\n",
    "        broker=broker,\n",
    "        force_refresh=False,\n",
    "    )\n",
    "    if \"time\" in df.columns and \"close\" in df.columns:\n",
    "        df = df[[\"time\", \"open\", \"high\", \"low\", \"close\", \"tick_volume\"]].dropna()\n",
    "        df[\"time\"] = pd.to_datetime(df[\"time\"])\n",
    "        df = df.set_index(\"time\")\n",
    "        for col in [\"open\", \"high\", \"low\", \"close\", \"tick_volume\"]:\n",
    "            data[(sym, col)] = df[col]\n",
    "prices = pd.DataFrame(data)\n",
    "print(prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Feature Engineering ---\n",
    "from feature_engineering import engineer_features\n",
    "symbol = \"EURUSD\"\n",
    "features = engineer_features(prices, symbol)\n",
    "print(features.head())"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Target Creation ---\n",
    "target = (prices[(symbol, \"close\")].shift(-1) > prices[(symbol, \"close\")]).astype(int)\n",
    "common_index = features.index.intersection(target.index)\n",
    "features = features.loc[common_index]\n",
    "target = target.loc[common_index]\n",
    "print(\"features shape:\", features.shape)\n",
    "print(\"target shape:\", target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Rolling Window, Train/Test Split, Model Training ---\n",
    "from model_utils import create_rolling_windows, train_test_split_rolling, train_cnn_lstm_model, evaluate_cnn_lstm_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_names = features.columns.tolist()\n",
    "features_scaled = StandardScaler().fit_transform(features)\n",
    "lookback = 20\n",
    "X = create_rolling_windows(features_scaled, lookback)\n",
    "y = target.values[lookback:]\n",
    "X_train, X_test, y_train, y_test = train_test_split_rolling(X, y, test_size=0.2)\n",
    "model, history = train_cnn_lstm_model(X_train, y_train, X_test, y_test, X_train.shape[1:], epochs=10, batch_size=32)\n",
    "acc, report = evaluate_cnn_lstm_model(model, X_test, y_test)\n",
    "print(\"Test accuracy:\", acc)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Feature Set Comparison and Permutation Importance ---\n",
    "from feature_set_analysis import compute_permutation_importance, compare_feature_sets, evaluate_and_save_feature_sets\n",
    "\n",
    "manual_feature_sets = {\n",
    "    \"Indicators only\": ['rsi', 'macd', 'momentum', 'cci'],\n",
    "    \"All features\": feature_names\n",
    "}\n",
    "results_df, best_row = evaluate_and_save_feature_sets(features, y, manual_feature_sets, symbol, lookback_window=lookback, model_fn=None, epochs=10, batch_size=32)\n",
    "print(results_df)\n",
    "\n",
    "# Permutation importance for best feature set\n",
    "best_features = best_row[\"Features\"]\n",
    "X_best = features[best_features].dropna().values\n",
    "features_scaled_best = StandardScaler().fit_transform(X_best)\n",
    "X_seq_best = create_rolling_windows(features_scaled_best, lookback)\n",
    "y_seq_best = y[-len(X_seq_best):]\n",
    "split = int(len(X_seq_best) * 0.8)\n",
    "X_train_best, X_test_best = X_seq_best[:split], X_seq_best[split:]\n",
    "y_train_best, y_test_best = y_seq_best[:split], y_seq_best[split:]\n",
    "model_best, _ = train_cnn_lstm_model(X_train_best, y_train_best, X_test_best, y_test_best, X_train_best.shape[1:], epochs=10, batch_size=32)\n",
    "importances = compute_permutation_importance(model_best, X_test_best, y_test_best, best_features)\n",
    "importance_df = pd.DataFrame(importances, columns=[\"Feature\", \"Importance\"])\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=importance_df, x=\"Importance\", y=\"Feature\")\n",
    "plt.title(f\"Feature Importance via Permutation: {symbol}\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
