{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74993638",
   "metadata": {},
   "source": [
    "## Runtime Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51afa8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-configurable parameters\n",
    "symbols_to_predict = ['EURUSD=X', 'GBPUSD=X']\n",
    "date_start = '2015-01-01'\n",
    "date_end = '2024-01-01'\n",
    "lookback_window = 20  # Number of days for the rolling input window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a997c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Processing symbol: EURUSD=X\n",
      "\n",
      "🔁 Processing symbol: GBPUSD=X\n"
     ]
    }
   ],
   "source": [
    "for symbol_to_predict in symbols_to_predict:\n",
    "    print(f\"\\n🔁 Processing symbol: {symbol_to_predict}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95089f71",
   "metadata": {},
   "source": [
    "# 📈 CNN + LSTM Forex Prediction using RCS + Technical Indicators\n",
    "This notebook builds a CNN+LSTM hybrid model to predict EURUSD price direction using Relative Currency Strength and common technical indicators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dd8034",
   "metadata": {},
   "source": [
    "## Step 1: Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03bdad9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (0.2.41)\n",
      "Requirement already satisfied: ta in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (2.32.3)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (5.2.2)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (4.2.2)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (2.4.4)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (3.17.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from scikit-learn) (1.14.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\projects\\finance\\platform\\fin-base-orchestration\\.conda\\lib\\site-packages (from requests>=2.31->yfinance) (2024.7.4)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split, TimeSeriesSplit\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, confusion_matrix, classification_report\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, concatenate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "    !pip install yfinance ta scikit-learn pandas numpy matplotlib seaborn\n",
    "\n",
    "    import yfinance as yf\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import ta\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "    from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, BatchNormalization, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c210ea",
   "metadata": {},
   "source": [
    "## Optional: Download Data from Polygon.io (if API key is available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "408a319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ POLYGON_API_KEY not set, using Yahoo Finance.\n"
     ]
    }
   ],
   "source": [
    "    import os\n",
    "    import requests\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    POLYGON_API_KEY = os.getenv(\"POLYGON_API_KEY\")  # set in your environment\n",
    "\n",
    "    def get_polygon_data(symbol, multiplier=1, timespan=\"day\", from_date=\"2015-01-01\", to_date=\"2024-01-01\", limit=5000):\n",
    "        url = f\"https://api.polygon.io/v2/aggs/ticker/C:{symbol}/range/{multiplier}/{timespan}/{from_date}/{to_date}\"\n",
    "        params = {\n",
    "            \"adjusted\": \"true\",\n",
    "            \"sort\": \"asc\",\n",
    "            \"limit\": limit,\n",
    "            \"apiKey\": POLYGON_API_KEY\n",
    "        }\n",
    "        r = requests.get(url, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Failed to download {symbol}: {r.status_code}\")\n",
    "            return None\n",
    "        data = r.json().get(\"results\", [])\n",
    "        df = pd.DataFrame(data)\n",
    "        df['t'] = pd.to_datetime(df['t'], unit='ms')\n",
    "        df.set_index('t', inplace=True)\n",
    "        df = df.rename(columns={'c': 'close'})\n",
    "        return df[['close']]\n",
    "\n",
    "    # Example: download EURUSD if API key is present\n",
    "    if POLYGON_API_KEY:\n",
    "        print(\"🔄 Using Polygon.io for data...\")\n",
    "        symbols = ['EURUSD', 'GBPUSD', 'USDJPY', 'AUDUSD', 'USDCAD', 'EURJPY', 'GBPJPY']\n",
    "        data = {}\n",
    "        for sym in symbols:\n",
    "            df = get_polygon_data(sym, from_date=\"2015-01-01\", to_date=\"2024-01-01\")\n",
    "            if df is not None:\n",
    "                data[sym] = df.rename(columns={'close': sym})\n",
    "        if len(data) >= 3:\n",
    "            prices = pd.concat(data.values(), axis=1).dropna()\n",
    "        else:\n",
    "            print(\"⚠️ Not enough Polygon data, falling back to Yahoo Finance.\")\n",
    "    else:\n",
    "        print(\"ℹ️ POLYGON_API_KEY not set, using Yahoo Finance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24d40d",
   "metadata": {},
   "source": [
    "## Step 2: Download OHLC Data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1cf303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get ticker 'EURUSD=X' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['EURUSD=X']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "Failed to get ticker 'GBPUSD=X' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GBPUSD=X']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "Failed to get ticker 'USDJPY=X' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['USDJPY=X']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "Failed to get ticker 'AUDUSD=X' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AUDUSD=X']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "Failed to get ticker 'USDCAD=X' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['USDCAD=X']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "Failed to get ticker 'EURJPY=X' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['EURJPY=X']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n",
      "Failed to get ticker 'GBPJPY=X' reason: Expecting value: line 1 column 1 (char 0)\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['GBPJPY=X']: YFTzMissingError('$%ticker%: possibly delisted; No timezone found')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EURUSD=X</th>\n",
       "      <th>GBPUSD=X</th>\n",
       "      <th>USDJPY=X</th>\n",
       "      <th>AUDUSD=X</th>\n",
       "      <th>USDCAD=X</th>\n",
       "      <th>EURJPY=X</th>\n",
       "      <th>GBPJPY=X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EURUSD=X, GBPUSD=X, USDJPY=X, AUDUSD=X, USDCAD=X, EURJPY=X, GBPJPY=X]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    symbols = ['EURUSD=X', 'GBPUSD=X', 'USDJPY=X', 'AUDUSD=X', 'USDCAD=X', 'EURJPY=X', 'GBPJPY=X']\n",
    "    data = {}\n",
    "    for sym in symbols:\n",
    "        df = yf.download(sym, start='2015-01-01', end='2024-01-01')\n",
    "        df = df[['Close']].rename(columns={'Close': sym})\n",
    "        data[sym] = df\n",
    "    prices = pd.concat(data.values(), axis=1)\n",
    "    prices.columns = symbols\n",
    "    prices.dropna(inplace=True)\n",
    "    prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4539f",
   "metadata": {},
   "source": [
    "## Step 3: Calculate Log Returns and Relative Currency Strength (RCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aba1b24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JPY</th>\n",
       "      <th>USD</th>\n",
       "      <th>AUD</th>\n",
       "      <th>GBP</th>\n",
       "      <th>EUR</th>\n",
       "      <th>CAD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [JPY, USD, AUD, GBP, EUR, CAD]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    def compute_rcs(logrets):\n",
    "        currencies = list(set([s[:3] for s in logrets.columns] + [s[3:6] for s in logrets.columns]))\n",
    "        rcs_data = {c: [] for c in currencies}\n",
    "        for i in range(len(logrets)):\n",
    "            row = logrets.iloc[i]\n",
    "            daily_strength = {c: 0 for c in currencies}\n",
    "            counts = {c: 0 for c in currencies}\n",
    "            for pair, ret in row.items():\n",
    "                base, quote = pair[:3], pair[3:]\n",
    "                daily_strength[base] += ret\n",
    "                daily_strength[quote] -= ret\n",
    "                counts[base] += 1\n",
    "                counts[quote] += 1\n",
    "            for c in currencies:\n",
    "                avg = daily_strength[c] / counts[c] if counts[c] else 0\n",
    "                rcs_data[c].append(avg)\n",
    "        return pd.DataFrame(rcs_data, index=logrets.index)\n",
    "\n",
    "    log_returns = np.log(prices / prices.shift(1)).dropna()\n",
    "    rcs = compute_rcs(log_returns)\n",
    "    rcs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a10b8",
   "metadata": {},
   "source": [
    "## Step 4: Calculate Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "    tech_df = prices.copy()\n",
    "    target = tech_df['EURUSD=X'].shift(-1) > tech_df['EURUSD=X']\n",
    "    target = target.astype(int).iloc[20:-1]\n",
    "\n",
    "    indicators = pd.DataFrame(index=tech_df.index)\n",
    "    indicators['rsi'] = ta.momentum.RSIIndicator(close=tech_df['EURUSD=X']).rsi()\n",
    "    indicators['macd'] = ta.trend.MACD(tech_df['EURUSD=X']).macd()\n",
    "    indicators['momentum'] = ta.momentum.ROCIndicator(close=tech_df['EURUSD=X']).roc()\n",
    "    indicators['cci'] = ta.trend.CCIIndicator(high=tech_df['EURUSD=X'], low=tech_df['EURUSD=X'], close=tech_df['EURUSD=X']).cci()\n",
    "    indicators = indicators.join(rcs).dropna()\n",
    "\n",
    "    features = indicators.iloc[20:-1]\n",
    "    features = StandardScaler().fit_transform(features)\n",
    "\n",
    "    X = np.array([features[i-20:i] for i in range(20, len(features))])\n",
    "    y = target.values\n",
    "    X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6819d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Feature Engineering\n",
    "from ta.volatility import BollingerBands, AverageTrueRange\n",
    "from ta.trend import ADXIndicator\n",
    "from ta.momentum import StochasticOscillator, ROCIndicator\n",
    "from ta.utils import dropna\n",
    "\n",
    "# Ensure indicators have no NaNs\n",
    "data = dropna(indicators)\n",
    "\n",
    "# Expanded Technical Indicators\n",
    "data['atr'] = AverageTrueRange(high=data['high'], low=data['low'], close=data['close']).average_true_range()\n",
    "data['adx'] = ADXIndicator(high=data['high'], low=data['low'], close=data['close']).adx()\n",
    "data['stoch_k'] = StochasticOscillator(high=data['high'], low=data['low'], close=data['close']).stoch()\n",
    "data['stoch_d'] = StochasticOscillator(high=data['high'], low=data['low'], close=data['close']).stoch_signal()\n",
    "data['roc'] = ROCIndicator(close=data['close']).roc()\n",
    "data['bbw'] = BollingerBands(close=data['close']).bollinger_wband()\n",
    "\n",
    "# Lagged/Engineered Features\n",
    "data['return_1d'] = data['close'].pct_change(1)\n",
    "data['return_3d'] = data['close'].pct_change(3)\n",
    "data['rolling_mean_5'] = data['close'].rolling(window=5).mean()\n",
    "data['rolling_std_5'] = data['close'].rolling(window=5).std()\n",
    "data['momentum_slope'] = data['close'].diff(1)\n",
    "\n",
    "# Placeholder Macro & Cross-Asset Features\n",
    "data['dxy'] = prices.get('DXY', pd.Series(index=data.index)).ffill()\n",
    "data['vix'] = prices.get('^VIX', pd.Series(index=data.index)).ffill()\n",
    "data['spx'] = prices.get('^GSPC', pd.Series(index=data.index)).ffill()\n",
    "data['gold_oil_ratio'] = prices.get('GC=F', pd.Series(index=data.index)) / prices.get('CL=F', pd.Series(index=data.index))\n",
    "\n",
    "# Time Features\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['month'] = data.index.month\n",
    "\n",
    "# Recombine indicators\n",
    "indicators = data.dropna()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456f1d2",
   "metadata": {},
   "source": [
    "## Step 5: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf25254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    split = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:split], X[split:]\n",
    "    y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3755dc29",
   "metadata": {},
   "source": [
    "## Step 6: Build CNN + LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_layer = Input(shape=(X.shape[1], X.shape[2]))\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu')(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(filters=32, kernel_size=3, activation='relu')(x)\n",
    "    x = LSTM(64, return_sequences=False)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c753469",
   "metadata": {},
   "source": [
    "## Step 7: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95692d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c7a1e8",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e45b0",
   "metadata": {},
   "source": [
    "## Step 9: Export Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39115f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Save model as .h5\n",
    "    model.save(\"cnn_lstm_model.h5\")\n",
    "\n",
    "    # Export to ONNX\n",
    "    import keras2onnx\n",
    "    onnx_model = keras2onnx.convert_keras(model, model.name)\n",
    "    import onnx\n",
    "    onnx.save_model(onnx_model, \"cnn_lstm_model.onnx\")\n",
    "    print(\"✅ Model exported to cnn_lstm_model.h5 and cnn_lstm_model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faadbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Save model\n",
    "    model.save(f\"model_{symbol_to_predict}.h5\")\n",
    "\n",
    "    # Export to ONNX\n",
    "    import keras2onnx\n",
    "    onnx_model = keras2onnx.convert_keras(model, model.name)\n",
    "    import onnx\n",
    "    onnx.save_model(onnx_model, f\"model_{symbol_to_predict}.onnx\")\n",
    "    print(f\"✅ Exported: model_{symbol_to_predict}.h5 and .onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29355349",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Simple backtest\n",
    "    probs = model.predict(X_test).flatten()\n",
    "    threshold = 0.5\n",
    "    signals = np.where(probs > threshold, 1, -1)\n",
    "    ret = np.log(prices[symbol_to_predict].shift(-1) / prices[symbol_to_predict]).iloc[-len(signals):]\n",
    "    strategy_returns = ret.values * signals\n",
    "\n",
    "    cum_ret = np.cumsum(strategy_returns)\n",
    "    cum_bh = np.cumsum(ret.values)\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(cum_ret, label=f'{symbol_to_predict} Strategy')\n",
    "    plt.plot(cum_bh, label='Buy & Hold', linestyle='--')\n",
    "    plt.title(f\"Cumulative Returns: {symbol_to_predict}\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2798f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ All models completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eacdd5",
   "metadata": {},
   "source": [
    "## Step 11: Feature Importance via Permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046866b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_permutation_importance(model, X_val, y_val, feature_names):\n",
    "    base_preds = (model.predict(X_val) > 0.5).astype(int)\n",
    "    base_acc = accuracy_score(y_val, base_preds)\n",
    "    importances = []\n",
    "\n",
    "    for i in range(X_val.shape[2]):\n",
    "        X_permuted = copy.deepcopy(X_val)\n",
    "        np.random.shuffle(X_permuted[:, :, i])\n",
    "        perm_preds = (model.predict(X_permuted) > 0.5).astype(int)\n",
    "        perm_acc = accuracy_score(y_val, perm_preds)\n",
    "        importance = base_acc - perm_acc\n",
    "        importances.append((feature_names[i], importance))\n",
    "\n",
    "    return sorted(importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Extract last 20 days of indicators used (same as model inputs)\n",
    "feature_names = indicators.columns.tolist()\n",
    "\n",
    "# Compute and display importances\n",
    "importances = compute_permutation_importance(model, X_test, y_test, feature_names)\n",
    "importance_df = pd.DataFrame(importances, columns=[\"Feature\", \"Importance\"])\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=importance_df, x=\"Importance\", y=\"Feature\")\n",
    "plt.title(f\"Feature Importance via Permutation: {symbol_to_predict}\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8a0dc",
   "metadata": {},
   "source": [
    "## Step 12: Feature Set Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daac8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- SWITCHABLE FEATURE SELECTION ENGINE ---\n",
    "\n",
    "import shap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Select strategy\n",
    "feature_selection_strategy = \"manual\"  # Options: \"manual\", \"permutation\", \"shap\"\n",
    "\n",
    "# Define feature sets to test (used if manual)\n",
    "manual_feature_sets = {\n",
    "    \"RCS only\": rcs.columns.tolist(),\n",
    "    \"Indicators only\": ['rsi', 'macd', 'momentum', 'cci'],\n",
    "    \"RCS + RSI + MACD\": rcs.columns.tolist() + ['rsi', 'macd'],\n",
    "    \"All features\": indicators.columns.tolist()\n",
    "}\n",
    "\n",
    "# Prepare unified data matrix\n",
    "feature_matrix = indicators.copy()\n",
    "target = (tech_df[symbol_to_predict].shift(-1) > tech_df[symbol_to_predict]).astype(int).iloc[20:-1]\n",
    "feature_matrix = feature_matrix.iloc[20:-1]\n",
    "scaled_features = StandardScaler().fit_transform(feature_matrix)\n",
    "X = np.array([scaled_features[i-lookback_window:i] for i in range(lookback_window, len(scaled_features))])\n",
    "y = target.values[lookback_window:]\n",
    "\n",
    "selected_feature_sets = {}\n",
    "\n",
    "if feature_selection_strategy == \"manual\":\n",
    "    selected_feature_sets = manual_feature_sets\n",
    "\n",
    "elif feature_selection_strategy == \"permutation\":\n",
    "    print(\"🔁 Running permutation-based feature importance...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(feature_matrix, target)\n",
    "    result = permutation_importance(rf, feature_matrix, target, n_repeats=10, random_state=42)\n",
    "    importances = pd.Series(result.importances_mean, index=feature_matrix.columns).sort_values(ascending=False)\n",
    "    top_feats = importances.head(10).index.tolist()\n",
    "    selected_feature_sets = {\"Top 10 Permutation\": top_feats}\n",
    "\n",
    "elif feature_selection_strategy == \"shap\":\n",
    "    print(\"📊 Running SHAP-based feature importance...\")\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(feature_matrix, target)\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    shap_values = explainer.shap_values(feature_matrix)\n",
    "    shap_sum = np.abs(shap_values[1]).mean(axis=0)\n",
    "    shap_importance = pd.Series(shap_sum, index=feature_matrix.columns).sort_values(ascending=False)\n",
    "    top_feats = shap_importance.head(10).index.tolist()\n",
    "    selected_feature_sets = {\"Top 10 SHAP\": top_feats}\n",
    "\n",
    "print(\"✅ Selected feature sets:\")\n",
    "print(selected_feature_sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc573210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify best by accuracy\n",
    "best_row = results_df.sort_values(by='Accuracy', ascending=False).iloc[0]\n",
    "results_df['Selected Features'] = list(feature_sets.values())\n",
    "\n",
    "# Save all results and best row to CSV\n",
    "results_df.to_csv(f'feature_set_results_{symbol_to_predict}.csv', index=False)\n",
    "best_row.to_frame().T.to_csv(f'best_feature_set_{symbol_to_predict}.csv', index=False)\n",
    "\n",
    "print(f\"📁 Saved results to feature_set_results_{symbol_to_predict}.csv\")\n",
    "print(f\"🏆 Best set saved to best_feature_set_{symbol_to_predict}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78452524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def cli_main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--mode\", choices=[\"train\", \"export\"], default=\"train\", help=\"Run training or export\")\n",
    "    parser.add_argument(\"--feature_strategy\", choices=[\"manual\", \"permutation\", \"shap\"], default=\"manual\")\n",
    "    parser.add_argument(\"--symbol\", type=str, default=\"EURUSD\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    global feature_selection_strategy, symbol_to_predict\n",
    "    feature_selection_strategy = args.feature_strategy\n",
    "    symbol_to_predict = args.symbol\n",
    "\n",
    "    if args.mode == \"train\":\n",
    "        print(f\"🔁 Running training for {symbol_to_predict} using '{feature_selection_strategy}' features...\")\n",
    "        # Main block is already under __name__ guard\n",
    "        if __name__ == \"__main__\":\n",
    "            pass  # triggers main loop\n",
    "    elif args.mode == \"export\":\n",
    "        print(\"🧠 Exporting model (not implemented here). Use inference.py.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cli_main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff640ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import load_or_fetch, load_twelve_data\n",
    "\n",
    "# Example with Twelve Data (can be switched based on CLI/config)\n",
    "symbol = config['symbol']\n",
    "provider = config.get('provider', 'twelvedata')\n",
    "api_key = config['api_keys'][provider]\n",
    "\n",
    "# Use selected loader function\n",
    "provider_loaders = {\n",
    "    \"twelvedata\": load_twelve_data,\n",
    "    \"polygon\": load_polygon_data,\n",
    "    \"alphavantage\": load_alpha_vantage,\n",
    "    \"currencystack\": load_currencystack,\n",
    "    \"tiingo\": load_tiingo\n",
    "}\n",
    "\n",
    "df = load_or_fetch(\n",
    "    symbol=symbol,\n",
    "    provider=provider,\n",
    "    loader_func=provider_loaders[provider],\n",
    "    api_key=api_key,\n",
    "    interval=config.get(\"interval\", \"1min\"),\n",
    "    outputsize=config.get(\"outputsize\", 500),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f153267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "def export_models(model, model_name=\"best_model\"):\n",
    "    # Save Keras HDF5 model\n",
    "    h5_path = f\"{model_name}.h5\"\n",
    "    model.save(h5_path)\n",
    "    print(f\"✅ Saved Keras model to: {h5_path}\")\n",
    "\n",
    "    # Save ONNX model\n",
    "    try:\n",
    "        import tf2onnx\n",
    "        import onnx\n",
    "\n",
    "        spec = (tf.TensorSpec((None, *model.input.shape[1:]), tf.float32),)\n",
    "        onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
    "        onnx_path = f\"{model_name}.onnx\"\n",
    "        onnx.save(onnx_model, onnx_path)\n",
    "        print(f\"✅ Saved ONNX model to: {onnx_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ ONNX export failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # --- RUN TRAINING AND EVALUATION ---\n",
    "    results = []\n",
    "\n",
    "    for test_name, selected_features in selected_feature_sets.items():\n",
    "        print(f\"\\n🔎 Testing feature set: {test_name}\")\n",
    "        X_selected = indicators[selected_features].dropna()\n",
    "        y_target = (tech_df[symbol_to_predict].shift(-1) > tech_df[symbol_to_predict]).astype(int)\n",
    "        common_index = X_selected.index.intersection(y_target.index)\n",
    "        X_selected = X_selected.loc[common_index]\n",
    "        y_target = y_target.loc[common_index]\n",
    "\n",
    "        # Scale features\n",
    "        X_scaled = StandardScaler().fit_transform(X_selected)\n",
    "\n",
    "        # Create sequences for LSTM\n",
    "        X_seq = np.array([X_scaled[i-lookback_window:i] for i in range(lookback_window, len(X_scaled))])\n",
    "        y_seq = y_target.values[lookback_window:]\n",
    "\n",
    "        # Train/test split\n",
    "        split_index = int(len(X_seq) * 0.8)\n",
    "        X_train, X_test = X_seq[:split_index], X_seq[split_index:]\n",
    "        y_train, y_test = y_seq[:split_index], y_seq[split_index:]\n",
    "\n",
    "        # Reshape for CNN+LSTM\n",
    "        X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "        X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))\n",
    "\n",
    "        # Model\n",
    "        model = create_cnn_lstm_model(X_train.shape[1:])\n",
    "        history = model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_split=0.1)\n",
    "        accuracy = model.evaluate(X_test, y_test, verbose=0)[1]\n",
    "\n",
    "        # Predict returns\n",
    "        preds = model.predict(X_test).flatten()\n",
    "        predicted_signal = (preds > 0.5).astype(int)\n",
    "        actual_returns = tech_df[symbol_to_predict].pct_change().fillna(0).values[-len(predicted_signal):]\n",
    "        strategy_return = (predicted_signal * actual_returns).sum()\n",
    "\n",
    "        print(f\"✅ Accuracy: {accuracy:.4f}, Return: {strategy_return:.4f}\")\n",
    "        results.append((test_name, accuracy, strategy_return, selected_features))\n",
    "\n",
    "    # Save and export results\n",
    "    results_df = pd.DataFrame(results, columns=[\"Feature Set\", \"Accuracy\", \"Return\", \"Features\"])\n",
    "    results_df.to_csv(f'feature_set_results_{symbol_to_predict}.csv', index=False)\n",
    "    best_row = results_df.sort_values(by='Accuracy', ascending=False).iloc[0]\n",
    "    best_row.to_frame().T.to_csv(f'best_feature_set_{symbol_to_predict}.csv', index=False)\n",
    "    print(\"📁 Results saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
